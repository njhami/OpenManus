# Global LLM configuration
[llm]
model = "Qwen/QwQ-32B"
base_url = "https://api.siliconflow.cn/v1/chat/completions"
api_key = "sk-fzqiloildbbynqmcpjygcwzhbigkffoxnytafcsqsaypzpkd"
max_tokens = 4096
temperature = 0.0

# Optional configuration for specific LLM models
[llm.vision]
model = "Qwen/QwQ-32B"
base_url = "https://api.siliconflow.cn/v1/chat/completions"
api_key = "sk-fzqiloildbbynqmcpjygcwzhbigkffoxnytafcsqsaypzpkd"
